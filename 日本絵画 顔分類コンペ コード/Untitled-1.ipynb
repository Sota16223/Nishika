{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対応表のパスを設定\n",
    "csv_path = '/Users/sota/Documents/Nishika/日本絵画 顔分類コンペ コード/data/train.csv'\n",
    "data_dir = '/Users/sota/Documents/Nishika/日本絵画 顔分類コンペ コード/data/train'\n",
    "\n",
    "# 対応表を読み込み\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df_filtered = df[df['gender_status'] != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データとラベルを格納するリスト\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "# データの読み込み\n",
    "for index, row in df_filtered.iterrows():\n",
    "    img_path = os.path.join(data_dir, row['image'])  # 'image' 列を使用\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        x_data.append(img)\n",
    "        y_data.append(row['gender_status'])  # 'gender_status' 列を使用\n",
    "    else:\n",
    "        print(f\"画像が見つからないか、読み込めませんでした: {img_path}\")\n",
    "\n",
    "# NumPy配列に変換\n",
    "x_data = np.array(x_data).reshape(-1, 100, 100, 1)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# クラス重みを計算\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_data), y=y_data)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# データをトレーニングセットと検証セットに分割\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.3, random_state=42, stratify=y_data)\n",
    "\n",
    "# データのシャッフル\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "x_val, y_val = shuffle(x_val, y_val, random_state=42)\n",
    "\n",
    "# ラベルをカテゴリカルデータに変換\n",
    "y_train_categorical = to_categorical(y_train, num_classes=8)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "inputs = Input(shape=(100, 100, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Flatten()(x) \n",
    "outputs = Dense(8, activation='softmax')(x)\n",
    "\n",
    "history_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# モデルのコンパイル\n",
    "history_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 早期終了のコールバックを設定\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 15:26:55.620729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.2209 - loss: 2.2186 - val_accuracy: 0.2406 - val_loss: 1.9210\n",
      "Epoch 2/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.3665 - loss: 1.6413 - val_accuracy: 0.2052 - val_loss: 2.1722\n",
      "Epoch 3/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.3767 - loss: 1.6382 - val_accuracy: 0.3601 - val_loss: 1.6273\n",
      "Epoch 4/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.4090 - loss: 1.5352 - val_accuracy: 0.1706 - val_loss: 2.1188\n",
      "Epoch 5/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.4441 - loss: 1.2956 - val_accuracy: 0.2862 - val_loss: 2.0157\n",
      "Epoch 6/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.4596 - loss: 1.3308 - val_accuracy: 0.4057 - val_loss: 1.6911\n",
      "Epoch 7/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.4599 - loss: 1.3199 - val_accuracy: 0.3506 - val_loss: 1.7201\n",
      "Epoch 8/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.4817 - loss: 1.2842 - val_accuracy: 0.1730 - val_loss: 2.6101\n",
      "Epoch 9/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.4990 - loss: 1.1990 - val_accuracy: 0.2822 - val_loss: 1.8999\n",
      "Epoch 10/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5048 - loss: 1.2219 - val_accuracy: 0.4017 - val_loss: 1.7049\n",
      "Epoch 11/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5210 - loss: 1.1279 - val_accuracy: 0.2712 - val_loss: 1.9219\n",
      "Epoch 12/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5425 - loss: 1.0571 - val_accuracy: 0.3506 - val_loss: 1.8781\n",
      "Epoch 13/50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5408 - loss: 1.1023 - val_accuracy: 0.4025 - val_loss: 1.9790\n"
     ]
    }
   ],
   "source": [
    "# モデルの訓練\n",
    "history = history_model.fit(x_train, y_train_categorical\n",
    "                                     , epochs=50, batch_size=64\n",
    "                                     , validation_data=(x_val, y_val_categorical)\n",
    "                                     , class_weight=class_weights_dict, callbacks=[early_stopping]\n",
    "                                     , shuffle=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "予測結果が /Users/sota/Documents/Nishika/日本絵画 顔分類コンペ コード/data//predictions.csv に保存されました。\n"
     ]
    }
   ],
   "source": [
    "# テストデータのディレクトリパスを設定\n",
    "test_data_dir = '/Users/sota/Documents/Nishika/日本絵画 顔分類コンペ コード/data/test'\n",
    "\n",
    "# テストデータの画像を読み込み、前処理\n",
    "x_test = []\n",
    "image_names = []\n",
    "\n",
    "for img_name in os.listdir(test_data_dir):\n",
    "    img_path = os.path.join(test_data_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        x_test.append(img)\n",
    "        image_names.append(img_name)\n",
    "    else:\n",
    "        print(f\"画像が見つからないか、読み込めませんでした: {img_path}\")\n",
    "\n",
    "# NumPy配列に変換\n",
    "x_test = np.array(x_test).reshape(-1, 100, 100, 1)\n",
    "\n",
    "# 予測を行う\n",
    "predictions = history_model.predict(x_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 結果をDataFrameにまとめる\n",
    "results_df = pd.DataFrame({'image': image_names, 'gender_status': predicted_classes})\n",
    "\n",
    "# 結果をCSVファイルに保存\n",
    "results_csv_path = '/Users/sota/Documents/Nishika/日本絵画 顔分類コンペ コード/data//predictions.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f\"予測結果が {results_csv_path} に保存されました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nishika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
