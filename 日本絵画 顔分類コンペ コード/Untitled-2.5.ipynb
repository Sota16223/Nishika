{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorchチャレンジ失敗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込みと前処理\n",
    "csv_path = 'C:\\\\Users\\\\admin\\\\Documents\\\\testB\\\\data\\\\train.csv'\n",
    "data_dir = 'C:\\\\Users\\\\admin\\\\Documents\\\\testB\\\\data\\\\train\\\\train'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df_filtered = df[df['gender_status'] != 5]\n",
    "\n",
    "def center_crop_and_resize(img, size):\n",
    "    h, w, _ = img.shape\n",
    "    min_dim = min(h, w)\n",
    "    start_x = (w - min_dim) // 2\n",
    "    start_y = (h - min_dim) // 2\n",
    "    cropped_img = img[start_y:start_y + min_dim, start_x:start_x + min_dim]\n",
    "    resized_img = cv2.resize(cropped_img, (size, size))\n",
    "    return resized_img\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    img_path = os.path.join(data_dir, row['image'])\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = center_crop_and_resize(img, 224)\n",
    "        x_data.append(img)\n",
    "        y_data.append(row['gender_status'])\n",
    "    else:\n",
    "        print(f\"画像が見つからないか、読み込めませんでした: {img_path}\")\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各カテゴリの画像の枚数を数える\n",
    "category_counts = df['gender_status'].value_counts()\n",
    "\n",
    "# 結果を表示\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"カテゴリ {category} の画像枚数: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスの不均等調整（クラス5の重みを無視）\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_data),  # クラス5も含むクラス全体を指定\n",
    "    y=y_data\n",
    ")\n",
    "\n",
    "# クラス5の重みをゼロに設定\n",
    "class_weights = np.array(class_weights)  # Numpy配列に変換\n",
    "#class_weights[5] = 0  # クラス5の重みをゼロに設定\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Tensor形式に変換してPyTorchに渡す\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "weights_tensor = weights_tensor.to(device)\n",
    "# 損失関数の設定\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "print(\"Class Weights Dictionary:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainデータとtestデータをシャッフルしてクラスの均等性を揃える\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.3, random_state=42,stratify=y_data)\n",
    "\n",
    "# PyTorch Dataset作成\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.x_data[idx]\n",
    "        label = self.y_data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ拡張と変換\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(360),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train, transform=transform)\n",
    "val_dataset = CustomDataset(x_val, y_val, transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model = models.resnet50(pretrained=True)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "base_model.fc = nn.Sequential(\n",
    "    nn.Linear(base_model.fc.in_features, 256),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Dropout(0.25),\n",
    "    nn.Linear(256, 7),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights)).to(device))\n",
    "optimizer = optim.Adam(base_model.fc.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングループの定義\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        # モデルをトレーニングモードに設定\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        # トレーニングデータを処理\n",
    "        for images, labels in train_loader:\n",
    "            images = images.float()\n",
    "            labels = labels.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # モデルを検証モードに設定\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# トレーニングループの実行\n",
    "train_model(base_model, train_loader, val_loader, criterion, optimizer, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# トレーニングループの定義\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        # モデルをトレーニングモードに設定\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        # トレーニングデータを処理\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(torch.long)  # 交差エントロピー損失関数は `Long` 型を期待\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images).to(torch.float32)  # `torch.float32` に変換\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 修正\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # モデルを検証モードに設定\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)  # デバイスに送る\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)  # 修正\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# トレーニングループの実行\n",
    "train_model(base_model, train_loader, val_loader, criterion, optimizer, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポック数\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "# 損失のプロット\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, 'ro-', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'bo-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 精度のプロット\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, 'ro-', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'bo-', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# プロットの表示\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのディレクトリパスを設定\n",
    "test_data_dir = 'C:\\\\Users\\\\adomin\\\\Documents\\\\testB\\\\data\\\\test\\\\test'\n",
    "\n",
    "# テストデータの画像を読み込み、前処理\n",
    "x_test = []\n",
    "image_names = []\n",
    "\n",
    "for img_name in os.listdir(test_data_dir):\n",
    "    img_path = os.path.join(test_data_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        x_test.append(img)\n",
    "        image_names.append(img_name)\n",
    "    else:\n",
    "        print(f\"画像が見つからないか、読み込めませんでした: {img_path}\")\n",
    "\n",
    "# PyTorch Tensorへの変換\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "x_test_tensor = torch.stack([transform(img) for img in x_test])  # テストデータをTensor形式に変換\n",
    "x_test_tensor = x_test_tensor.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# 予測を行う\n",
    "base_model.eval()  # モデルを評価モードに切り替え\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # 勾配計算を無効化\n",
    "    for img_tensor in x_test_tensor:\n",
    "        img_tensor = img_tensor.unsqueeze(0)  # バッチサイズ1に対応させる\n",
    "        output = base_model(img_tensor)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "        predictions.append(predicted_class)\n",
    "\n",
    "# 結果をDataFrameにまとめる\n",
    "results_df = pd.DataFrame({'image': image_names, 'gender_status': predictions})\n",
    "\n",
    "# 結果をCSVファイルに保存\n",
    "results_csv_path = 'C:\\\\Users\\\\adomin\\\\Documents\\\\testB\\\\data\\\\predictions8.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f\"予測結果が {results_csv_path} に保存されました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
